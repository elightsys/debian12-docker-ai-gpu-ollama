# ğŸ§  Debian 12 + Docker + NVIDIA RTX 4070 + Ollama Setup

This project provides a complete step-by-step guide for setting up a GPU-accelerated AI environment using:

- ğŸ§ Debian 12
- ğŸ³ Docker & Docker Compose
- âš™ï¸ NVIDIA RTX 4070 (with full CUDA support)
- ğŸ¤– [Ollama](https://ollama.com) AI model runner

The configuration supports FastAPI-based AI backends and is suitable for self-hosted solutions using Traefik, Redis, and GPU inference acceleration.

## ğŸ“š Contents

- ğŸ§© GPU Driver + CUDA installation
- ğŸ³ Docker & NVIDIA Container Toolkit
- ğŸ”§ Docker Compose setup for Ollama
- ğŸ” Integration with AI microservices (FastAPI, Redis)
- ğŸ§ª Verification and testing steps
- ğŸš§ Troubleshooting

## ğŸ“„ Full Documentation (PDF)

- ğŸ‡ºğŸ‡¸ [Download English PDF](pdf/Debian12-Docker-AI-GPU-Ollama-EN.pdf)
- ğŸ‡­ğŸ‡º [LetÃ¶ltÃ©s magyar nyelvÅ± PDF](pdf/Debian12-Docker-AI-GPU-Ollama-HU.pdf)

## ğŸ“‚ Folder Structure

```bash
/mnt/raid/docker/
â”œâ”€â”€ traefik/           # Reverse proxy
â”œâ”€â”€ webstack/          # PHP+MariaDB sites
â”œâ”€â”€ ai/                # AI backend (FastAPI + Ollama)
â”œâ”€â”€ monitoring/        # Grafana + Prometheus
â”œâ”€â”€ nginx/
â”œâ”€â”€ php/
â”œâ”€â”€ mariadb/
â”œâ”€â”€ phpmyadmin/
â””â”€â”€ tools/             # Watchtower, backup, CI/CD
